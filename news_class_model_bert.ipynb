{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_class_model_bert.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPFWOb0VnGnc4E95J6u+ryA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monash-tp37-project/iteration_1_model/blob/master/news_class_model_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# News Classification Model using BERT"
      ],
      "metadata": {
        "id": "iGAf9EGRdnHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmg6J7ifdWSE",
        "outputId": "be2cefcc-bba7-4d35-955b-c45e647f90a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install all packages needed\n",
        "\n",
        "#!pip3 install sklearn --upgrade\n",
        "#!pip3 install pickle --update\n",
        "!pip3 install transformers\n",
        "!pip3 install pymysql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoEmwEmjdarw",
        "outputId": "ac0b53a2-9cec-4b22-c43d-0334d81b942a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.7/dist-packages (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import all libraries needed\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nltk used for parsing and cleaning text\n",
        "import nltk\n",
        "import unicodedata\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from difflib import SequenceMatcher\n",
        "from scipy import spatial\n",
        "from itertools import combinations\n",
        "\n",
        "# used to acccess the sql database\n",
        "import pymysql\n",
        "# library that helps turn dataframes into sql tables\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import pickle\n",
        "\n",
        "## for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OHNoGHuda0L",
        "outputId": "19ad57bf-b360-47cb-fe6a-f5f8a7b75a7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GcGMR1a-da8m",
        "outputId": "e9d046aa-48df-486d-c8f5-a661dd5a37fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create connection\n",
        "connection = pymysql.connect(host='news-data-rdb.cqsnaejqwcpu.ap-southeast-2.rds.amazonaws.com',\n",
        "                             user='admin',\n",
        "                             password='badpassword1',\n",
        "                             db='news_data')"
      ],
      "metadata": {
        "id": "mNkusUsodbCl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query to retreive our data for the model\n",
        "SQL_Query = pd.read_sql_query(\n",
        "        '''\n",
        "        select\n",
        "        *\n",
        "        from news_table\n",
        "        ''', connection)"
      ],
      "metadata": {
        "id": "wvnej3kpdbH2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SQL_Query.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LooPBe4HdbNH",
        "outputId": "fa1586de-d5db-4013-e887-42f0f964ab68"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 926980 entries, 0 to 926979\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   news_id  926980 non-null  int64 \n",
            " 1   text     926980 non-null  object\n",
            " 2   label    926980 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 21.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SQL_Query[SQL_Query['label'] == 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "he65U1JrdbSY",
        "outputId": "bff0dfe6-56d0-4223-fc53-c7b5dddfe832"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        news_id                                               text  label\n",
              "1             1  flynn hillary clinton woman campus breitbart f...      0\n",
              "5             5  jackie mason hollywood love trump bombed north...      0\n",
              "7             7  benoît hamon wins french socialist party presi...      0\n",
              "8             8  excerpts draft script donald trump ampa black ...      0\n",
              "9             9  channel plan ukraine russia courtesy trump ass...      0\n",
              "...         ...                                                ...    ...\n",
              "794511   794511  chinese court jails rights lawyer years inciti...      0\n",
              "794512   794512  britain boris johnson jokes dead bodies libya ...      0\n",
              "794515   794515  senate hearings delayed wealthy trump nominees...      0\n",
              "794516   794516  obama expected sign zika drug development whit...      0\n",
              "794517   794517  nations affected immigration order stay list w...      0\n",
              "\n",
              "[765023 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ee04287-0a90-4e48-ab51-56d471c9a03c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>jackie mason hollywood love trump bombed north...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>benoît hamon wins french socialist party presi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>excerpts draft script donald trump ampa black ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>channel plan ukraine russia courtesy trump ass...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794511</th>\n",
              "      <td>794511</td>\n",
              "      <td>chinese court jails rights lawyer years inciti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794512</th>\n",
              "      <td>794512</td>\n",
              "      <td>britain boris johnson jokes dead bodies libya ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794515</th>\n",
              "      <td>794515</td>\n",
              "      <td>senate hearings delayed wealthy trump nominees...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794516</th>\n",
              "      <td>794516</td>\n",
              "      <td>obama expected sign zika drug development whit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>794517</th>\n",
              "      <td>794517</td>\n",
              "      <td>nations affected immigration order stay list w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>765023 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ee04287-0a90-4e48-ab51-56d471c9a03c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ee04287-0a90-4e48-ab51-56d471c9a03c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ee04287-0a90-4e48-ab51-56d471c9a03c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = SQL_Query.sample(n=150000, random_state = 1)"
      ],
      "metadata": {
        "id": "VTXJW0NzdbWm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.reset_index(drop=True,inplace=True)\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "W4UzcWVZdba0",
        "outputId": "37105220-576c-4117-bc0c-ce919d5db0b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        news_id                                               text  label\n",
              "0        361876  brief television broadcasts says shaw enter li...      0\n",
              "1        440155  hsbc wins dismissal madoff customer class acti...      0\n",
              "2        259634  brief regeneron says prescriptions written dup...      0\n",
              "3        654131  trump body plans leave white house soon offici...      0\n",
              "4        514981  brief signatures initiative distinguish forms ...      0\n",
              "...         ...                                                ...    ...\n",
              "249995   701645  dollar stalls trump speech reveals little trad...      0\n",
              "249996   284438  russia social media widespread meddling politi...      0\n",
              "249997   832541  titanichoops maybe unnecessary maybe necessary...      1\n",
              "249998    77461  billion plug long term care insurance hole exp...      0\n",
              "249999   542229  sterling month lows dollar brexit weigh graphi...      0\n",
              "\n",
              "[250000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c9f40b2-89d7-4281-b5f4-ec90725c046c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>361876</td>\n",
              "      <td>brief television broadcasts says shaw enter li...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>440155</td>\n",
              "      <td>hsbc wins dismissal madoff customer class acti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259634</td>\n",
              "      <td>brief regeneron says prescriptions written dup...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>654131</td>\n",
              "      <td>trump body plans leave white house soon offici...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>514981</td>\n",
              "      <td>brief signatures initiative distinguish forms ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>701645</td>\n",
              "      <td>dollar stalls trump speech reveals little trad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>284438</td>\n",
              "      <td>russia social media widespread meddling politi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>832541</td>\n",
              "      <td>titanichoops maybe unnecessary maybe necessary...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>77461</td>\n",
              "      <td>billion plug long term care insurance hole exp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>542229</td>\n",
              "      <td>sterling month lows dollar brexit weigh graphi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c9f40b2-89d7-4281-b5f4-ec90725c046c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c9f40b2-89d7-4281-b5f4-ec90725c046c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c9f40b2-89d7-4281-b5f4-ec90725c046c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_index = list(train_df.index.values)"
      ],
      "metadata": {
        "id": "3X7Tsu-yfCxs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SQL_Query.drop(train_index, inplace=True)\n",
        "SQL_Query.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "nOcjqxW0fh-J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = SQL_Query.sample(n=15000, random_state = 1)\n",
        "test_df.reset_index(drop=True, inplace=True)\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ukz29Lb7dbfC",
        "outputId": "7261ce39-1851-481a-c8db-cad87e38fb6d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       news_id                                               text  label\n",
              "0       917986            trump greatest creator https kapcbhmsil      1\n",
              "1       614752  brief domino pizza announces share repurchase ...      0\n",
              "2       844005  cincinnatidays reds drop indians cueto possibl...      1\n",
              "3       278973  senior official meets taliban negotiators qata...      0\n",
              "4       802838  wdfx podestaemails clinton camp received heads...      1\n",
              "...        ...                                                ...    ...\n",
              "24995   366730  truckers strike likely ground second quarter b...      0\n",
              "24996   620426  turkey widens post coup purge demands hand cle...      0\n",
              "24997   819383  chelsea clinton visit ohio thursday https wmzs...      1\n",
              "24998   604931  futures extend losses democrat tipped alabama ...      0\n",
              "24999   371428  china imports tonnes customs beijing april reu...      0\n",
              "\n",
              "[25000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-526d5daa-df1d-4b99-acb5-caf82dcaa7eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>917986</td>\n",
              "      <td>trump greatest creator https kapcbhmsil</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>614752</td>\n",
              "      <td>brief domino pizza announces share repurchase ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>844005</td>\n",
              "      <td>cincinnatidays reds drop indians cueto possibl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>278973</td>\n",
              "      <td>senior official meets taliban negotiators qata...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>802838</td>\n",
              "      <td>wdfx podestaemails clinton camp received heads...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>366730</td>\n",
              "      <td>truckers strike likely ground second quarter b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>620426</td>\n",
              "      <td>turkey widens post coup purge demands hand cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>819383</td>\n",
              "      <td>chelsea clinton visit ohio thursday https wmzs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>604931</td>\n",
              "      <td>futures extend losses democrat tipped alabama ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>371428</td>\n",
              "      <td>china imports tonnes customs beijing april reu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-526d5daa-df1d-4b99-acb5-caf82dcaa7eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-526d5daa-df1d-4b99-acb5-caf82dcaa7eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-526d5daa-df1d-4b99-acb5-caf82dcaa7eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KwNnMb_PdbnJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activating the GPU\n",
        "# Main menu->Runtime->Change Runtime Type\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x18RL1TTgvLN",
        "outputId": "3761d896-68ac-430a-feb7-28c094cb7353"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the Hugging Face PyTorch Interface for Bert\n",
        "# !pip install pytorch-pretrained-bert pytorch-nlp\n",
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "tO4knC9ggvvF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import AdamW, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ge_71_1Ygv5_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying CUDA as the device for Torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UKY5_vMOgwE5",
        "outputId": "8af01997-0072-4dd0-876e-e34d8fc13f96"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sentence, label lists and adding Bert tokens\n",
        "sentences = train_df.text.values\n",
        "\n",
        "# Adding CLS and SEP tokens at the beginning and end of each sentence for BERT\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = train_df.label.values"
      ],
      "metadata": {
        "id": "-Ic2ymEzgwRi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activating the BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzxtu9_IdbrW",
        "outputId": "f94bfccd-fc56-4439-cfc7-27d6fd8309c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'brief', 'television', 'broadcasts', 'says', 'shaw', 'enter', 'licence', 'agreement', 'reuters', 'television', 'broadcasts', 'company', 'shaw', 'entered', 'licence', 'agreement', 'source', 'text', 'e', '##iko', '##n', 'company', 'coverage', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing the data\n",
        "# Set the maximum sequence length, in this case 128\n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 512\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "clU7r94kdbvj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "4lBYcIDOdb0L"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into train and validation sets\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=1, test_size=0.1)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=1, test_size=0.1)"
      ],
      "metadata": {
        "id": "bgZV2u-Fdb4Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting all the data into torch tensors\n",
        "# Torch tensors are the required datatype for our model\n",
        "\n",
        "# x train\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "# y train\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "# \n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "kmD2kjo6db8O"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a Batch Size and Creating and Iterator\n",
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "r6pzE5kOdcAy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert Configuration\n",
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "# Transformer Installation\n",
        "try:\n",
        "  import transformers\n",
        "except:\n",
        "  print(\"Installing transformers\")\n",
        "  !pip -qq install transformers\n",
        "  \n",
        "from transformers import BertModel, BertConfig\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model from the bert-base-uncased style configuration\n",
        "model = BertModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config\n",
        "print(configuration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQE9oZX0dcFA",
        "outputId": "b56f054d-9fa8-4904-9dcf-a5192030757b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Hugging Face Bert Uncased Base Model \n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-h9bG7wdcJS",
        "outputId": "48ccd3a5-6896-463f-f977-da355c781198"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer Grouped Parameters\n",
        "# This code is taken from:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
        "\n",
        "# Don't apply weight decay to any parameters whose names include these tokens.\n",
        "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "# Separate the `weight` parameters from the `bias` parameters. \n",
        "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
        "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
        "optimizer_grouped_parameters = [\n",
        "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.1},\n",
        "    \n",
        "    # Filter for parameters which *do* include those.\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n",
        "# the names."
      ],
      "metadata": {
        "id": "Uqv0e27GdcO4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the Hyperparemeters for the Training Loop \n",
        "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "#                      lr=2e-5,\n",
        "#                      warmup=.1)\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "# `train_dataloader` contains batched data so `len(train_dataloader)` gives \n",
        "# us the number of batches.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "C4-8ffK0heBo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Accuracy Measurement Function\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "LUjbCUSSheKC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Y4J8fv_kheVq",
        "outputId": "07fb9f37-2b61-43d4-93c1-00536e9ec225"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |  428785 KB |  428785 KB |  428785 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |     497 KB |     497 KB |     497 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |  428785 KB |  428785 KB |  428785 KB |       0 B  |\\n|       from large pool |  428288 KB |  428288 KB |  428288 KB |       0 B  |\\n|       from small pool |     497 KB |     497 KB |     497 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  483328 KB |  483328 KB |  483328 KB |       0 B  |\\n|       from large pool |  481280 KB |  481280 KB |  481280 KB |       0 B  |\\n|       from small pool |    2048 KB |    2048 KB |    2048 KB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   54542 KB |   54552 KB |  265210 KB |  210667 KB |\\n|       from large pool |   52992 KB |   52992 KB |  263168 KB |  210176 KB |\\n|       from small pool |    1550 KB |    2042 KB |    2042 KB |     491 KB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     203    |     203    |     203    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     128    |     128    |     128    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     203    |     203    |     203    |       0    |\\n|       from large pool |      75    |      75    |      75    |       0    |\\n|       from small pool |     128    |     128    |     128    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      21    |      21    |      21    |       0    |\\n|       from large pool |      20    |      20    |      20    |       0    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      19    |      19    |      20    |       1    |\\n|       from large pool |      18    |      18    |      19    |       1    |\\n|       from small pool |       1    |       1    |       1    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Training Loop\n",
        "t = [] \n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    loss = outputs['loss']\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update the learning rate.\n",
        "    scheduler.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits['logits'].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_ZNQLrFhegl",
        "outputId": "7b62dbb9-11ae-4fb3-8b32-a0ee6e944f18"
      },
      "execution_count": 31,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.014886597030863456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [47:54<2:23:43, 2874.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.996521113243762\n",
            "Train loss: 0.006649670311904279\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [1:35:51<1:35:52, 2876.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9946817018554063\n",
            "Train loss: 0.003392063355328627\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [2:23:48<47:56, 2876.55s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9979206653870761\n",
            "Train loss: 0.001562126439092686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 4/4 [3:11:44<00:00, 2876.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9982405630198337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Evaluation\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "4rwWLWGBheqx",
        "outputId": "e5b0d492-3ba6-4142-d26a-99da9ceb9d5e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test our model on new data"
      ],
      "metadata": {
        "id": "0IQP9wo_h0TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentence and label lists\n",
        "sentences = test_df.text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = test_df.label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 512\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "  \n",
        "batch_size = 16  \n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ryMQNb30he08"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits['logits'].detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ],
      "metadata": {
        "id": "fMJcgnTnhwN9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  matthews = matthews_corrcoef(true_labels[i],\n",
        "                 np.argmax(predictions[i], axis=1).flatten())\n",
        "  matthews_set.append(matthews)"
      ],
      "metadata": {
        "id": "-9yPWIMnhwWC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matthew's Evaluation on the Whole Dataset\n",
        "# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "matthews_corrcoef(flat_true_labels, flat_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0Vy8Mvkhwe4",
        "outputId": "55868a27-8f6f-407c-dde1-ef145e1b22b9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9992497184187745"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the trained model and tokenizer."
      ],
      "metadata": {
        "id": "toB8q-9G1zaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/tokenizer_150k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAo_ShTPhwmj",
        "outputId": "d7abfab8-71f8-47ce-a81e-92254dcb58ff"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/colab_data/tokenizer_200k/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/colab_data/tokenizer_200k/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/colab_data/tokenizer_200k/vocab.txt',\n",
              " '/content/drive/MyDrive/colab_data/tokenizer_200k/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/model_150k_512\")"
      ],
      "metadata": {
        "id": "wJJkRld8hwtP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1rsysoL7hwzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LmX43Tk_he_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BXNLqxZydcTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IjC5gG3bdcYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQXxXeUcdceN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}