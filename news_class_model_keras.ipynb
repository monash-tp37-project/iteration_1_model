{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cae1781f",
      "metadata": {
        "id": "cae1781f"
      },
      "source": [
        "# News Classification Model using Keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuQo6wmQ6e3c",
        "outputId": "726c3dda-a937-40de-be43-555b9ccaa1a0"
      },
      "id": "EuQo6wmQ6e3c",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install all packages needed\n",
        "\n",
        "#!pip3 install sklearn --upgrade\n",
        "#!pip3 install pickle --update\n",
        "!pip3 install transformers\n",
        "!pip3 install pymysql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLXAMvRNi42m",
        "outputId": "c6a81f0d-fa4e-4df6-fee1-7ed4fdd09a53"
      },
      "id": "nLXAMvRNi42m",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.7/dist-packages (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "58c6fcf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58c6fcf5",
        "outputId": "62bddeba-76a6-4418-b564-9aaec5ee4a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import all libraries needed\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nltk used for parsing and cleaning text\n",
        "import nltk\n",
        "import unicodedata\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from difflib import SequenceMatcher\n",
        "from scipy import spatial\n",
        "from itertools import combinations\n",
        "\n",
        "# used to acccess the sql database\n",
        "import pymysql\n",
        "# library that helps turn dataframes into sql tables\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import pickle\n",
        "\n",
        "## for deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "10adb8b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "10adb8b5",
        "outputId": "5afcfd3b-42fd-4dbb-dbc2-e22a6d952162"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "83eada8b",
      "metadata": {
        "id": "83eada8b"
      },
      "outputs": [],
      "source": [
        "# create connection\n",
        "connection = pymysql.connect(host='news-data-rdb.cqsnaejqwcpu.ap-southeast-2.rds.amazonaws.com',\n",
        "                             user='admin',\n",
        "                             password='badpassword1',\n",
        "                             db='news_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "51d33e76",
      "metadata": {
        "id": "51d33e76"
      },
      "outputs": [],
      "source": [
        "# SQL query to retreive our data for the model\n",
        "SQL_Query = pd.read_sql_query(\n",
        "        '''\n",
        "        select\n",
        "        *\n",
        "        from new_table\n",
        "        ''', connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "4cb02bf3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4cb02bf3",
        "outputId": "fe248222-0d2d-4790-c58f-167efdd6d91a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        news_id                                               text  label\n",
              "1             1  flynn hillary clinton woman campus breitbart f...      0\n",
              "5             5  jackie mason hollywood love trump bombed north...      0\n",
              "7             7  benoît hamon wins french socialist party presi...      0\n",
              "8             8  excerpts draft script donald trump ampa black ...      0\n",
              "9             9  channel plan ukraine russia courtesy trump ass...      0\n",
              "...         ...                                                ...    ...\n",
              "808939   808939  moscow cairo sign deal friday resume russian f...      0\n",
              "808940   808940  transcripts clinton wall street talks released...      0\n",
              "808941   808941  syrian government condemns embassy jerusalem s...      0\n",
              "808942   808942  greece plays financial impact deal athens reut...      0\n",
              "808945   808945  iranians fear economic hardship united trump a...      0\n",
              "\n",
              "[773831 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d0d0ba3-d35e-4d7c-82c0-f0fe42dbd413\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>jackie mason hollywood love trump bombed north...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>benoît hamon wins french socialist party presi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>excerpts draft script donald trump ampa black ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>channel plan ukraine russia courtesy trump ass...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808939</th>\n",
              "      <td>808939</td>\n",
              "      <td>moscow cairo sign deal friday resume russian f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808940</th>\n",
              "      <td>808940</td>\n",
              "      <td>transcripts clinton wall street talks released...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808941</th>\n",
              "      <td>808941</td>\n",
              "      <td>syrian government condemns embassy jerusalem s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808942</th>\n",
              "      <td>808942</td>\n",
              "      <td>greece plays financial impact deal athens reut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808945</th>\n",
              "      <td>808945</td>\n",
              "      <td>iranians fear economic hardship united trump a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>773831 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d0d0ba3-d35e-4d7c-82c0-f0fe42dbd413')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d0d0ba3-d35e-4d7c-82c0-f0fe42dbd413 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d0d0ba3-d35e-4d7c-82c0-f0fe42dbd413');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "SQL_Query[SQL_Query['label'] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = SQL_Query.sample(n=50000, random_state = 1)\n",
        "train_df.reset_index(drop=True,inplace=True)\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oQYP0O7EX8-0",
        "outputId": "435397f3-f4ec-486f-c380-a3cdd82af454"
      },
      "id": "oQYP0O7EX8-0",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       news_id                                               text  label\n",
              "0       270800  brief proact appoints acting reuters proact gr...      0\n",
              "1       518775  tesla says agreement chinese battery maker lis...      0\n",
              "2       711281  booker points boosts suns past spurs editorsno...      0\n",
              "3       869205  isikoff exclusive abruptly scraps potus meet g...      1\n",
              "4       584066  world number willis wins wimbledon dreamland l...      0\n",
              "...        ...                                                ...    ...\n",
              "49995   467174  italian mafia stronghold women soccer players ...      0\n",
              "49996   599812  brief ourpalm profit rises percent april reute...      0\n",
              "49997   567333  brief convano announces mothers april march re...      0\n",
              "49998   298928  refugees seek asylum geneva reuters refugee ag...      0\n",
              "49999   722013  brief freedom insurance group says remains ent...      0\n",
              "\n",
              "[50000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-133c7e2b-9d9f-446b-857f-ccb5ee5423c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>270800</td>\n",
              "      <td>brief proact appoints acting reuters proact gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518775</td>\n",
              "      <td>tesla says agreement chinese battery maker lis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>711281</td>\n",
              "      <td>booker points boosts suns past spurs editorsno...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>869205</td>\n",
              "      <td>isikoff exclusive abruptly scraps potus meet g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>584066</td>\n",
              "      <td>world number willis wins wimbledon dreamland l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>467174</td>\n",
              "      <td>italian mafia stronghold women soccer players ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>599812</td>\n",
              "      <td>brief ourpalm profit rises percent april reute...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>567333</td>\n",
              "      <td>brief convano announces mothers april march re...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>298928</td>\n",
              "      <td>refugees seek asylum geneva reuters refugee ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>722013</td>\n",
              "      <td>brief freedom insurance group says remains ent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-133c7e2b-9d9f-446b-857f-ccb5ee5423c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-133c7e2b-9d9f-446b-857f-ccb5ee5423c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-133c7e2b-9d9f-446b-857f-ccb5ee5423c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[train_df['label'] == 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m4mX9Jqus2kS",
        "outputId": "9f631c74-5fca-4c02-ff68-b8e37a35a501"
      },
      "id": "m4mX9Jqus2kS",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       news_id                                               text  label\n",
              "0       270800  brief proact appoints acting reuters proact gr...      0\n",
              "1       518775  tesla says agreement chinese battery maker lis...      0\n",
              "2       711281  booker points boosts suns past spurs editorsno...      0\n",
              "4       584066  world number willis wins wimbledon dreamland l...      0\n",
              "6       343803  chicago blackhawks playerwatch artemi panarin ...      0\n",
              "...        ...                                                ...    ...\n",
              "49995   467174  italian mafia stronghold women soccer players ...      0\n",
              "49996   599812  brief ourpalm profit rises percent april reute...      0\n",
              "49997   567333  brief convano announces mothers april march re...      0\n",
              "49998   298928  refugees seek asylum geneva reuters refugee ag...      0\n",
              "49999   722013  brief freedom insurance group says remains ent...      0\n",
              "\n",
              "[41185 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95fc35b9-6699-4e19-8921-70287b9331c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>270800</td>\n",
              "      <td>brief proact appoints acting reuters proact gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518775</td>\n",
              "      <td>tesla says agreement chinese battery maker lis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>711281</td>\n",
              "      <td>booker points boosts suns past spurs editorsno...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>584066</td>\n",
              "      <td>world number willis wins wimbledon dreamland l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>343803</td>\n",
              "      <td>chicago blackhawks playerwatch artemi panarin ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>467174</td>\n",
              "      <td>italian mafia stronghold women soccer players ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>599812</td>\n",
              "      <td>brief ourpalm profit rises percent april reute...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>567333</td>\n",
              "      <td>brief convano announces mothers april march re...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>298928</td>\n",
              "      <td>refugees seek asylum geneva reuters refugee ag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>722013</td>\n",
              "      <td>brief freedom insurance group says remains ent...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41185 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95fc35b9-6699-4e19-8921-70287b9331c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95fc35b9-6699-4e19-8921-70287b9331c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95fc35b9-6699-4e19-8921-70287b9331c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "797c11fb",
      "metadata": {
        "id": "797c11fb",
        "outputId": "65fe19f2-a6b0-458e-eea6-53d44eca8ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      news_id                                               text  label\n",
              "0      270800  brief proact appoints acting reuters proact gr...      0\n",
              "1      518775  tesla says agreement chinese battery maker lis...      0\n",
              "2      711281  booker points boosts suns past spurs editorsno...      0\n",
              "3      869205  isikoff exclusive abruptly scraps potus meet g...      1\n",
              "4      584066  world number willis wins wimbledon dreamland l...      0\n",
              "...       ...                                                ...    ...\n",
              "9995   321023  orleans saints playerwatch delvin breaux misse...      0\n",
              "9996   925456  asyounotwish bothered muslims feel trump rule ...      1\n",
              "9997   885461  weneedtrump trump rallies little different hil...      1\n",
              "9998   249932  brief smart final stores reports financial res...      0\n",
              "9999   838764  workers trump jobs created stock market manufa...      1\n",
              "\n",
              "[10000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3faa2017-37e1-4b03-a9db-0f716dc978a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>270800</td>\n",
              "      <td>brief proact appoints acting reuters proact gr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>518775</td>\n",
              "      <td>tesla says agreement chinese battery maker lis...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>711281</td>\n",
              "      <td>booker points boosts suns past spurs editorsno...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>869205</td>\n",
              "      <td>isikoff exclusive abruptly scraps potus meet g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>584066</td>\n",
              "      <td>world number willis wins wimbledon dreamland l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>321023</td>\n",
              "      <td>orleans saints playerwatch delvin breaux misse...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>925456</td>\n",
              "      <td>asyounotwish bothered muslims feel trump rule ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>885461</td>\n",
              "      <td>weneedtrump trump rallies little different hil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>249932</td>\n",
              "      <td>brief smart final stores reports financial res...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>838764</td>\n",
              "      <td>workers trump jobs created stock market manufa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3faa2017-37e1-4b03-a9db-0f716dc978a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3faa2017-37e1-4b03-a9db-0f716dc978a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3faa2017-37e1-4b03-a9db-0f716dc978a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "test_df = SQL_Query.sample(n=10000, random_state = 1)\n",
        "test_df.reset_index(drop=True,inplace=True)\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[test_df['label'] == 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zhojC6v0tITb",
        "outputId": "b6687e9e-f7dd-4aed-a66b-a57a7618b452"
      },
      "id": "zhojC6v0tITb",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      news_id                                               text  label\n",
              "3      869205  isikoff exclusive abruptly scraps potus meet g...      1\n",
              "5      822789  dbhnbuckhead imarchwithlinda dopey liberals ex...      1\n",
              "10      20422  happened hillary supporting professor decided ...      1\n",
              "21     923304  blackpounduk claudiawebbe umojaisourmight http...      1\n",
              "26     828469  norleansdaily live boulevard waggaman close fi...      1\n",
              "...       ...                                                ...    ...\n",
              "9975   856691             easterin words candy hangover progress      1\n",
              "9979   857293  ocamericans clinton manufactured fakenews msnb...      1\n",
              "9996   925456  asyounotwish bothered muslims feel trump rule ...      1\n",
              "9997   885461  weneedtrump trump rallies little different hil...      1\n",
              "9999   838764  workers trump jobs created stock market manufa...      1\n",
              "\n",
              "[1783 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b1ce2db-b32d-4c6b-92f4-2e005735929f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>869205</td>\n",
              "      <td>isikoff exclusive abruptly scraps potus meet g...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>822789</td>\n",
              "      <td>dbhnbuckhead imarchwithlinda dopey liberals ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20422</td>\n",
              "      <td>happened hillary supporting professor decided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>923304</td>\n",
              "      <td>blackpounduk claudiawebbe umojaisourmight http...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>828469</td>\n",
              "      <td>norleansdaily live boulevard waggaman close fi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9975</th>\n",
              "      <td>856691</td>\n",
              "      <td>easterin words candy hangover progress</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9979</th>\n",
              "      <td>857293</td>\n",
              "      <td>ocamericans clinton manufactured fakenews msnb...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>925456</td>\n",
              "      <td>asyounotwish bothered muslims feel trump rule ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>885461</td>\n",
              "      <td>weneedtrump trump rallies little different hil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>838764</td>\n",
              "      <td>workers trump jobs created stock market manufa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1783 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b1ce2db-b32d-4c6b-92f4-2e005735929f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b1ce2db-b32d-4c6b-92f4-2e005735929f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b1ce2db-b32d-4c6b-92f4-2e005735929f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SQL_Query.drop(index=list(test_df.index.values) ,inplace=True)\n",
        "#SQL_Query.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "51UKUWCPChrA"
      },
      "id": "51UKUWCPChrA",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#news_sql_df.to_csv(f'{current_dir}/drive/MyDrive/colab_data/news_sql_df.csv', index=False)"
      ],
      "metadata": {
        "id": "Xq_9jUlo6c7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "0ec2ad2d-a3c2-48b7-8158-1d195610717d"
      },
      "id": "Xq_9jUlo6c7r",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d4290fccc37f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnews_sql_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{current_dir}/drive/MyDrive/colab_data/news_sql_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'news_sql_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#news_sql_df = pd.read_csv(f'{current_dir}/drive/MyDrive/colab_data/news_sql_df.csv', index_col=False)"
      ],
      "metadata": {
        "id": "KEEemZ8t6dGO"
      },
      "id": "KEEemZ8t6dGO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#news_sql_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b_0xXXQ5_ciD",
        "outputId": "da11dc54-6cf6-4dcd-e592-21e193081ab2"
      },
      "id": "b_0xXXQ5_ciD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       news_id                                               text  label\n",
              "0            0  house aide comey letter jason chaffetz tweeted...      1\n",
              "1            1  flynn hillary clinton woman campus breitbart f...      0\n",
              "2            2  truth fired truth fired october tension intell...      1\n",
              "3            3  civilians killed single airstrike identified v...      1\n",
              "4            4  iranian woman jailed fictional unpublished sto...      1\n",
              "...        ...                                                ...    ...\n",
              "19995    19995  rembrandt proves chapter genesis rembrandt pro...      1\n",
              "19996    19996  obama rising west antichrist obama rising west...      1\n",
              "19997    19997  planet nibiru slovakia planet nibiru slovakia ...      1\n",
              "19998    19998  book alien races exposed book alien races expo...      1\n",
              "19999    19999  neil armstrong ships superior neil armstrong s...      1\n",
              "\n",
              "[20000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9a4db32-8b5e-4364-8b32-4bdaa139bc89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>house aide comey letter jason chaffetz tweeted...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>truth fired truth fired october tension intell...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>civilians killed single airstrike identified v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>19995</td>\n",
              "      <td>rembrandt proves chapter genesis rembrandt pro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>19996</td>\n",
              "      <td>obama rising west antichrist obama rising west...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>19997</td>\n",
              "      <td>planet nibiru slovakia planet nibiru slovakia ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>19998</td>\n",
              "      <td>book alien races exposed book alien races expo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>19999</td>\n",
              "      <td>neil armstrong ships superior neil armstrong s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9a4db32-8b5e-4364-8b32-4bdaa139bc89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9a4db32-8b5e-4364-8b32-4bdaa139bc89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9a4db32-8b5e-4364-8b32-4bdaa139bc89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5288b5e7",
      "metadata": {
        "id": "5288b5e7"
      },
      "outputs": [],
      "source": [
        "# Obtain the total words present in the dataset\n",
        "list_of_words = []\n",
        "for i in news_sql_df.text:\n",
        "  words = i.split(' ')\n",
        "  for j in words:\n",
        "      list_of_words.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain the total number of unique words\n",
        "total_words = len(list(set(list_of_words)))\n",
        "total_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9tAVqNXOsFB",
        "outputId": "a5e625b1-8522-4d3e-83b2-9ed46a03f012"
      },
      "id": "B9tAVqNXOsFB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118348"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610d4f5d",
      "metadata": {
        "id": "610d4f5d"
      },
      "outputs": [],
      "source": [
        "# split data into test and train \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(news_sql_df.text.to_list(), news_sql_df.label.to_list(), test_size = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3a3a33",
      "metadata": {
        "id": "cc3a3a33"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(analyzer = 'word',\n",
        "                            input = 'content',\n",
        "                            lowercase = True,\n",
        "                            token_pattern = '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "                            min_df = 3,\n",
        "                            ngram_range = (1,1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.fit(x_train)\n",
        "\n",
        "x_train = vectorizer.transform(x_train).toarray() # shape - (3,6)\n",
        "x_train = x_train[:, :, None] # shape - (3,6,1) since LSTM cells expects ndims = 3\n",
        "\n",
        "x_test = vectorizer.transform(x_test).toarray() # shape - (3,6)\n",
        "x_test = x_test[:, :, None] # shape - (3,6,1) since LSTM cells expects ndims = 3"
      ],
      "metadata": {
        "id": "GQxOK0Q4Fif3"
      },
      "id": "GQxOK0Q4Fif3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bc7a1d5",
      "metadata": {
        "id": "2bc7a1d5"
      },
      "outputs": [],
      "source": [
        "# turn binary labels intp a numpy array\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0cc04ca",
      "metadata": {
        "id": "f0cc04ca"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15112649",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15112649",
        "outputId": "bc12b38d-9ca1-461b-c9a4-da636f58c6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          7574272   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,648,641\n",
            "Trainable params: 7,648,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Sequential Model\n",
        "model = Sequential()\n",
        "\n",
        "# embeddidng layer to do PCA \n",
        "# total_words = defined the total number of vocabs \n",
        "model.add(Embedding(total_words, output_dim = 64))\n",
        "\n",
        "# Bi-Directional RNN and LSTM\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "\n",
        "# Dense layers\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1, activation= 'sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7762f165",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7762f165",
        "outputId": "afb2faa6-ffa7-4bbf-cb29-add20f2368d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r   1/1125 [..............................] - ETA: 104:31:44 - loss: 0.6945 - acc: 0.3750"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "#  validation_split = 0.1, use 10% of the data for cross validation\n",
        "model.fit(x_train, y_train, batch_size = 16, epochs = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9018f1e",
      "metadata": {
        "id": "d9018f1e"
      },
      "outputs": [],
      "source": [
        "# make prediction\n",
        "pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b59e79bb",
      "metadata": {
        "id": "b59e79bb"
      },
      "outputs": [],
      "source": [
        "# if the predicted value is >0.5 it is real else it is fake\n",
        "prediction = []\n",
        "for i in range(len(pred)):\n",
        "    if pred[i].item() > 0.5:\n",
        "        prediction.append(1)\n",
        "    else:\n",
        "        prediction.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a280587",
      "metadata": {
        "id": "5a280587"
      },
      "outputs": [],
      "source": [
        "# getting the accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(list(y_test), prediction)\n",
        "\n",
        "print(\"Model Accuracy : \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32806b7e",
      "metadata": {
        "id": "32806b7e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e24e29",
      "metadata": {
        "id": "b7e24e29"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04720b9b",
      "metadata": {
        "id": "04720b9b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f70e4b75",
      "metadata": {
        "id": "f70e4b75"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Library"
      ],
      "metadata": {
        "id": "8EZKCLI7EgW7"
      },
      "id": "8EZKCLI7EgW7"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_LVC7EUL7wbn"
      },
      "id": "_LVC7EUL7wbn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test of transformer "
      ],
      "metadata": {
        "id": "l62JbZLD7x04"
      },
      "id": "l62JbZLD7x04"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "9T_8lGO3Ee0B"
      },
      "id": "9T_8lGO3Ee0B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "17KEBom2EMLR"
      },
      "id": "17KEBom2EMLR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.tokenize('this is a new sentence')\n",
        "token_ids = tokenizer(tokens)"
      ],
      "metadata": {
        "id": "PUBz6HikEM1D"
      },
      "id": "PUBz6HikEM1D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids"
      ],
      "metadata": {
        "id": "burcM1-yEM-N"
      },
      "id": "burcM1-yEM-N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "favHBj3oENlj"
      },
      "id": "favHBj3oENlj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50b23f1e",
      "metadata": {
        "id": "50b23f1e"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('zero-shot-classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "979b62c8",
      "metadata": {
        "id": "979b62c8"
      },
      "outputs": [],
      "source": [
        "input = 'Trump was shot in the head this morning'\n",
        "res = classifier(input, candidate_labels = ['reliable news', 'fake news'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb304019",
      "metadata": {
        "id": "fb304019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6ce55f-cce5-4de2-887f-d411a809a2b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': ['news', 'fake news'],\n",
              " 'scores': [0.9644107818603516, 0.03558921441435814],\n",
              " 'sequence': 'Trump was shot in the head this morning'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6fmIDHwnF1wC"
      },
      "id": "6fmIDHwnF1wC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tvf-ge0ONTkR"
      },
      "id": "tvf-ge0ONTkR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actual Model"
      ],
      "metadata": {
        "id": "xMgMcwUBNVMa"
      },
      "id": "xMgMcwUBNVMa"
    },
    {
      "cell_type": "code",
      "source": [
        "#Activating the GPU\n",
        "# Main menu->Runtime->Change Runtime Type\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oNwUhMx8hyu",
        "outputId": "c6d7fc0e-bee5-4fa7-ec1c-7d0095dc97ff"
      },
      "id": "0oNwUhMx8hyu",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the Hugging Face PyTorch Interface for Bert\n",
        "# !pip install pytorch-pretrained-bert pytorch-nlp\n",
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "3tlGbZ-L8ies"
      },
      "id": "3tlGbZ-L8ies",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import AdamW, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "metadata": {
        "id": "-hV5oN7_8in2"
      },
      "id": "-hV5oN7_8in2",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying CUDA as the device for Torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VG7eh8QH8i01",
        "outputId": "4a918da7-06ad-4c3b-fbbb-de15c4d06393"
      },
      "id": "VG7eh8QH8i01",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sentence, label lists and adding Bert tokens\n",
        "sentences = train_df.text.values\n",
        "\n",
        "# Adding CLS and SEP tokens at the beginning and end of each sentence for BERT\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = train_df.label.values"
      ],
      "metadata": {
        "id": "cY_D8EeU8i_r"
      },
      "id": "cY_D8EeU8i_r",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Activating the BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (\"Tokenize the first sentence:\")\n",
        "print (tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42edm74w8jLq",
        "outputId": "b9270654-b708-4759-c9da-d12c635b24e0"
      },
      "id": "42edm74w8jLq",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize the first sentence:\n",
            "['[CLS]', 'brief', 'pro', '##act', 'appoint', '##s', 'acting', 'reuters', 'pro', '##act', 'group', 'jason', 'clark', 'chosen', 'resign', 'position', 'february', 'board', 'decided', 'appoint', 'peter', 'ja', '##ves', '##tad', 'acting', 'source', 'text', 'e', '##iko', '##n', 'company', 'coverage', 'g', '##dy', '##nia', 'news', '##room', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing the data\n",
        "# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "metadata": {
        "id": "V10QUheq8jYs"
      },
      "id": "V10QUheq8jYs",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "metadata": {
        "id": "iQ7alNYKB3FA"
      },
      "id": "iQ7alNYKB3FA",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting data into train and validation sets\n",
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "5sFd5bAyB3sY"
      },
      "id": "5sFd5bAyB3sY",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting all the data into torch tensors\n",
        "# Torch tensors are the required datatype for our model\n",
        "\n",
        "# x train\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "# y train\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "# \n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "9aan5JCUB36I"
      },
      "id": "9aan5JCUB36I",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting a Batch Size and Creating and Iterator\n",
        "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rMaSteM3B4Eo"
      },
      "id": "rMaSteM3B4Eo",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert Configuration\n",
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "# Transformer Installation\n",
        "try:\n",
        "  import transformers\n",
        "except:\n",
        "  print(\"Installing transformers\")\n",
        "  !pip -qq install transformers\n",
        "  \n",
        "from transformers import BertModel, BertConfig\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model from the bert-base-uncased style configuration\n",
        "model = BertModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config\n",
        "print(configuration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKGe29ki8jsv",
        "outputId": "b9fe58aa-89a4-436b-ada3-8f465ca4c3bd"
      },
      "id": "JKGe29ki8jsv",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Hugging Face Bert Uncased Base Model \n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMbExHBE8j5t",
        "outputId": "8b7acac8-74e0-4141-b5cd-646b206d7dc6"
      },
      "id": "xMbExHBE8j5t",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer Grouped Parameters\n",
        "# This code is taken from:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n",
        "\n",
        "# Don't apply weight decay to any parameters whose names include these tokens.\n",
        "# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "# Separate the `weight` parameters from the `bias` parameters. \n",
        "# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n",
        "# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n",
        "optimizer_grouped_parameters = [\n",
        "    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.1},\n",
        "    \n",
        "    # Filter for parameters which *do* include those.\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n",
        "# the names."
      ],
      "metadata": {
        "id": "86tN7nEeDGTV"
      },
      "id": "86tN7nEeDGTV",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the Hyperparemeters for the Training Loop \n",
        "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "#                      lr=2e-5,\n",
        "#                      warmup=.1)\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                  )\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "# `train_dataloader` contains batched data so `len(train_dataloader)` gives \n",
        "# us the number of batches.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "AvteJyWaDGy0"
      },
      "id": "AvteJyWaDGy0",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Accuracy Measurement Function\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "oNcyQJ6QDHeY"
      },
      "id": "oNcyQJ6QDHeY",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "TWpqlp03SR8j"
      },
      "id": "TWpqlp03SR8j",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "eXkRifXwSf81",
        "outputId": "2344d495-2e8e-42f9-b4e3-8eefbfa8e96f"
      },
      "id": "eXkRifXwSf81",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    1386 MB |   13439 MB |   60958 MB |   59572 MB |\\n|       from large pool |    1385 MB |   13436 MB |   60947 MB |   59562 MB |\\n|       from small pool |       1 MB |       3 MB |      11 MB |       9 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    1386 MB |   13439 MB |   60958 MB |   59572 MB |\\n|       from large pool |    1385 MB |   13436 MB |   60947 MB |   59562 MB |\\n|       from small pool |       1 MB |       3 MB |      11 MB |       9 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    1790 MB |   13550 MB |   13550 MB |   11760 MB |\\n|       from large pool |    1786 MB |   13546 MB |   13546 MB |   11760 MB |\\n|       from small pool |       4 MB |       4 MB |       4 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  412950 KB |  544079 KB |    5672 MB |    5269 MB |\\n|       from large pool |  410532 KB |  542628 KB |    5659 MB |    5258 MB |\\n|       from small pool |    2418 KB |    3017 KB |      13 MB |      11 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     621    |    1057    |    2545    |    1924    |\\n|       from large pool |     231    |     493    |    1471    |    1240    |\\n|       from small pool |     390    |     642    |    1074    |     684    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     621    |    1057    |    2545    |    1924    |\\n|       from large pool |     231    |     493    |    1471    |    1240    |\\n|       from small pool |     390    |     642    |    1074    |     684    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      61    |     207    |     207    |     146    |\\n|       from large pool |      59    |     205    |     205    |     146    |\\n|       from small pool |       2    |       2    |       2    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      70    |      91    |     664    |     594    |\\n|       from large pool |      57    |      82    |     319    |     262    |\\n|       from small pool |      13    |      13    |     345    |     332    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Training Loop\n",
        "t = [] \n",
        "\n",
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "  \n",
        "  \n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    loss = outputs['loss']\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update the learning rate.\n",
        "    scheduler.step()\n",
        "    \n",
        "    \n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    \n",
        "    \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits['logits'].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rlIysNxDHuN",
        "outputId": "9f836a41-e822-4994-8239-49902e1f8b52"
      },
      "id": "1rlIysNxDHuN",
      "execution_count": 46,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.044832345554324846\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 1/4 [16:59<50:57, 1019.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9892172523961661\n",
            "Train loss: 0.01803173258663156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 2/4 [34:09<34:11, 1025.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9906150159744409\n",
            "Train loss: 0.007381332644834526\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 3/4 [51:17<17:06, 1026.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9914137380191693\n",
            "Train loss: 0.002866848038857151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 4/4 [1:08:24<00:00, 1026.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9920127795527156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Evaluation\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "4UqWS3g9DH6h",
        "outputId": "5d25cca1-1a58-4d2b-b104-6b06ed7ccd41"
      },
      "id": "4UqWS3g9DH6h",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GRV6RLJ6DIGH"
      },
      "id": "GRV6RLJ6DIGH",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lSa05N__KTFx"
      },
      "id": "lSa05N__KTFx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test our model onb new data"
      ],
      "metadata": {
        "id": "2Kic104PKT6K"
      },
      "id": "2Kic104PKT6K"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentence and label lists\n",
        "sentences = test_df.text.values\n",
        "\n",
        "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
        "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
        "labels = test_df.label.values\n",
        "\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "  \n",
        "batch_size = 16  \n",
        "\n",
        "\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Ib-CFjvBDIPP"
      },
      "id": "Ib-CFjvBDIPP",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "  with torch.no_grad():\n",
        "    # Forward pass, calculate logit predictions\n",
        "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits['logits'].detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)"
      ],
      "metadata": {
        "id": "CCnbQ9aoDIa3"
      },
      "id": "CCnbQ9aoDIa3",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and evaluate each test batch using Matthew's correlation coefficient\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "matthews_set = []\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  matthews = matthews_corrcoef(true_labels[i],\n",
        "                 np.argmax(predictions[i], axis=1).flatten())\n",
        "  matthews_set.append(matthews)"
      ],
      "metadata": {
        "id": "HE4GaGW6DIks"
      },
      "id": "HE4GaGW6DIks",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Matthew's Evaluation on the Whole Dataset\n",
        "# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "matthews_corrcoef(flat_true_labels, flat_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gLukylbbqfX",
        "outputId": "eef5348d-acb5-4e5f-86b5-2ee00846e573"
      },
      "id": "4gLukylbbqfX",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9952244690268817"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## How to save a model\n",
        "\n",
        "# vectorizer\n",
        "https://stackoverflow.com/questions/64550503/huggingface-saving-tokenizer\n",
        "BASE_MODEL = \"distilbert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "tokenizer.save_pretrained(\"./models/tokenizer/\")\n",
        "tokenizer2 = DistilBertTokenizer.from_pretrained(\"./models/tokenizer/\")\n",
        "\n",
        "\n",
        "# model\n",
        "https://huggingface.co/docs/transformers/model_sharing\n",
        "pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n",
        "pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n",
        "\n",
        "\n",
        "\n",
        "https://stackoverflow.com/questions/64001128/load-a-pre-trained-model-from-disk-with-huggingface-transformers\n",
        "# python\n",
        "from transformers import BertTokenizer\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"/opt/word_embeddings/bert-base-uncased/\")\n",
        "'''"
      ],
      "metadata": {
        "id": "bune2QJQbqoy"
      },
      "id": "bune2QJQbqoy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/tokenizer_50k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzSO4rzVlDI3",
        "outputId": "e2dbd63f-7a8b-47c6-f309-f729f125d0b9"
      },
      "id": "YzSO4rzVlDI3",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/colab_data/tokenizer_50k/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/colab_data/tokenizer_50k/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/colab_data/tokenizer_50k/vocab.txt',\n",
              " '/content/drive/MyDrive/colab_data/tokenizer_50k/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/model_50k_128\")"
      ],
      "metadata": {
        "id": "9lvr6yrdmZAz"
      },
      "id": "9lvr6yrdmZAz",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2 = BertTokenizer.from_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/tokenizer_50k\")"
      ],
      "metadata": {
        "id": "IoFq2QynnCc4"
      },
      "id": "IoFq2QynnCc4",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = BertForSequenceClassification.from_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/model_50k_128\")"
      ],
      "metadata": {
        "id": "CU01tboVnc4p"
      },
      "id": "CU01tboVnc4p",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5OiaOokn25I",
        "outputId": "e3f783d0-1ece-4274-a6a1-c8b59fb0524d"
      },
      "id": "r5OiaOokn25I",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "wIYMx3M3n48J"
      },
      "id": "wIYMx3M3n48J",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "#from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# read in trained tokenizer and model\n",
        "tokenizer2 = BertTokenizer.from_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/tokenizer_50k\")\n",
        "model2 = BertForSequenceClassification.from_pretrained(f\"{current_dir}/drive/MyDrive/colab_data/model_50k_128\")\n",
        "sequences = [\"hillary clinton eats dead babies\"]\n",
        "\n",
        "# tokenize text input\n",
        "tokens = tokenizer2(sequences, padding=True, truncation=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "lu3Vdf_eoHa0"
      },
      "id": "lu3Vdf_eoHa0",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  # make predictions\n",
        "  output = model2(**tokens)\n",
        "  print(output)\n",
        "\n",
        "  # using a softmax activation function get discrete predictions\n",
        "  predictions = F.softmax(output.logits, dim=1)\n",
        "  labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "  # using a sigmoid function get continous predictions \n",
        "  labels1 = torch.sigmoid(predictions)\n",
        "  print(labels)\n",
        "  print(labels1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXCA_mUjoHlX",
        "outputId": "56383e52-997b-4dcf-9119-c824cee5221a"
      },
      "id": "OXCA_mUjoHlX",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-3.8595,  3.7022]]), hidden_states=None, attentions=None)\n",
            "tensor([[5.1970e-04, 9.9948e-01]])\n",
            "tensor([1])\n",
            "tensor([[0.5001, 0.7310]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tL49WHtMppxv"
      },
      "id": "tL49WHtMppxv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "news_class_model_keras.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}