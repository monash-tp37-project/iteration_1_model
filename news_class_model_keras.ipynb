{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae1781f",
   "metadata": {},
   "source": [
    "# News Classification Model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c6fcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/arminberger/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arminberger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import all libraries needed\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import langid\n",
    "\n",
    "# nltk used for parsing and cleaning text\n",
    "import nltk\n",
    "import unicodedata\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from difflib import SequenceMatcher\n",
    "from scipy import spatial\n",
    "from itertools import combinations\n",
    "\n",
    "# used to acccess the sql database\n",
    "import pymysql\n",
    "# library that helps turn dataframes into sql tables\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pickle\n",
    "\n",
    "## for deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Input, LSTM, Conv1D, MaxPool1D, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7ef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10adb8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/arminberger/Documents/GitHub/iteration_1_model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83eada8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection\n",
    "connection = pymysql.connect(host='news-data-rdb.cqsnaejqwcpu.ap-southeast-2.rds.amazonaws.com',\n",
    "                             user='admin',\n",
    "                             password='badpassword1',\n",
    "                             db='news_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d33e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to retreive our data for the model\n",
    "SQL_Query = pd.read_sql_query(\n",
    "    '''select\n",
    "        *\n",
    "        from new_table''', connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb02bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>house aide comey letter jason chaffetz tweeted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>truth fired truth fired october tension intell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>civilians killed single airstrike identified v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941403</th>\n",
       "      <td>941403</td>\n",
       "      <td>buzzfeed year awkward convo dude texting trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941404</th>\n",
       "      <td>941404</td>\n",
       "      <td>littlebytesnews tcot news variety facebook too...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941405</th>\n",
       "      <td>941405</td>\n",
       "      <td>signsinyork getting right company logo busines...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941406</th>\n",
       "      <td>941406</td>\n",
       "      <td>latest obama affirms continuity ties canada ht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941407</th>\n",
       "      <td>941407</td>\n",
       "      <td>futureguru upload online thats product work go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941408 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        news_id                                               text  label\n",
       "0             0  house aide comey letter jason chaffetz tweeted...      1\n",
       "1             1  flynn hillary clinton woman campus breitbart f...      0\n",
       "2             2  truth fired truth fired october tension intell...      1\n",
       "3             3  civilians killed single airstrike identified v...      1\n",
       "4             4  iranian woman jailed fictional unpublished sto...      1\n",
       "...         ...                                                ...    ...\n",
       "941403   941403  buzzfeed year awkward convo dude texting trump...      1\n",
       "941404   941404  littlebytesnews tcot news variety facebook too...      1\n",
       "941405   941405  signsinyork getting right company logo busines...      1\n",
       "941406   941406  latest obama affirms continuity ties canada ht...      1\n",
       "941407   941407  futureguru upload online thats product work go...      1\n",
       "\n",
       "[941408 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQL_Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7729b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data rereived in a query as a pandas dataframe\n",
    "news_sql_df = pd.DataFrame(SQL_Query, columns=['news_id', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "797c11fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>house aide comey letter jason chaffetz tweeted...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>flynn hillary clinton woman campus breitbart f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>truth fired truth fired october tension intell...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>civilians killed single airstrike identified v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941403</th>\n",
       "      <td>941403</td>\n",
       "      <td>buzzfeed year awkward convo dude texting trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941404</th>\n",
       "      <td>941404</td>\n",
       "      <td>littlebytesnews tcot news variety facebook too...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941405</th>\n",
       "      <td>941405</td>\n",
       "      <td>signsinyork getting right company logo busines...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941406</th>\n",
       "      <td>941406</td>\n",
       "      <td>latest obama affirms continuity ties canada ht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941407</th>\n",
       "      <td>941407</td>\n",
       "      <td>futureguru upload online thats product work go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941408 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        news_id                                               text  label\n",
       "0             0  house aide comey letter jason chaffetz tweeted...      1\n",
       "1             1  flynn hillary clinton woman campus breitbart f...      0\n",
       "2             2  truth fired truth fired october tension intell...      1\n",
       "3             3  civilians killed single airstrike identified v...      1\n",
       "4             4  iranian woman jailed fictional unpublished sto...      1\n",
       "...         ...                                                ...    ...\n",
       "941403   941403  buzzfeed year awkward convo dude texting trump...      1\n",
       "941404   941404  littlebytesnews tcot news variety facebook too...      1\n",
       "941405   941405  signsinyork getting right company logo busines...      1\n",
       "941406   941406  latest obama affirms continuity ties canada ht...      1\n",
       "941407   941407  futureguru upload online thats product work go...      1\n",
       "\n",
       "[941408 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sql_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288b5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "610d4f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(news_sql_df.text, news_sql_df.label, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3a3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                             input = 'content',\n",
    "                            lowercase = True,\n",
    "                            token_pattern = '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                            min_df = 3,\n",
    "                            ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b56ad454",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3330\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3331\u001b[0;31m                     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3332\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-8bcfd69ae0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# vectorize the training text input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_sql_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                 \u001b[0mremoved_terms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# vectorize the training text input \n",
    "vectorizer.fit_transform(news_sql_df.text.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d07d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the training text input \n",
    "x_train = vectorizer.transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec29e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b00c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b25a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0cc04ca",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15112649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "# embeddidng layer to do PCA \n",
    "# total_words = defined the total number of vocabs \n",
    "model.add(Embedding(total_words, output_dim = 1000))\n",
    "# model.add(Embedding(total_words, output_dim = 240))\n",
    "\n",
    "\n",
    "# Bi-Directional RNN and LSTM\n",
    "model.add(Bidirectional(LSTM(1000)))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dense(1, activation= 'sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc7a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn binary labels intp a numpy array\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "#  validation_split = 0.1, use 10% of the data for cross validation\n",
    "model.fit(x_train, y_train, batch_size = 64, validation_split = 0.1, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed68da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9018f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the predicted value is >0.5 it is real else it is fake\n",
    "prediction = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i].item() > 0.5:\n",
    "        prediction.append(1)\n",
    "    else:\n",
    "        prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a280587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(list(y_test), prediction)\n",
    "\n",
    "print(\"Model Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32806b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e24e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04720b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e4b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b23f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb304019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
